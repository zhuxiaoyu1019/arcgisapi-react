{"ast":null,"code":"/*\nAll material copyright ESRI, All Rights Reserved, unless otherwise specified.\nSee https://js.arcgis.com/4.20/esri/copyright.txt for details.\n*/\nimport { ReadLinearDepth as e } from \"../output/ReadLinearDepth.glsl.js\";\nimport { Reprojection as t, bindReprojectionUniforms as o } from \"./Reprojection.glsl.js\";\nimport { glsl as r } from \"../../shaderModules/interfaces.js\";\n\nfunction a(o, a) {\n  o.fragment.uniforms.add(\"nearFar\", \"vec2\"), o.fragment.uniforms.add(\"depthMapView\", \"sampler2D\"), o.fragment.uniforms.add(\"ssrViewMat\", \"mat4\"), o.fragment.uniforms.add(\"invResolutionHeight\", \"float\"), o.fragment.include(e), o.include(t), o.fragment.code.add(r`\n  const int maxSteps = ${a.highStepCount ? \"150;\" : \"75;\"}\n\n  vec4 applyProjectionMat(mat4 projectionMat, vec3 x)\n  {\n    vec4 projectedCoord =  projectionMat * vec4(x, 1.0);\n    projectedCoord.xy /= projectedCoord.w;\n    projectedCoord.xy = projectedCoord.xy*0.5 + 0.5;\n    return projectedCoord;\n  }\n\n  vec3 screenSpaceIntersection(vec3 dir, vec3 startPosition, vec3 viewDir, vec3 normal)\n  {\n    vec3 viewPos = startPosition;\n    vec3 viewPosEnd = startPosition;\n\n    // Project the start position to the screen\n    vec4 projectedCoordStart = applyProjectionMat(rpProjectionMat, viewPos);\n    vec3  Q0 = viewPos / projectedCoordStart.w; // homogeneous camera space\n    float k0 = 1.0/ projectedCoordStart.w;\n\n    // advance the position in the direction of the reflection\n    viewPos += dir;\n\n    vec4 projectedCoordVanishingPoint = applyProjectionMat(rpProjectionMat, dir);\n\n    // Project the advanced position to the screen\n    vec4 projectedCoordEnd = applyProjectionMat(rpProjectionMat, viewPos);\n    vec3  Q1 = viewPos / projectedCoordEnd.w; // homogeneous camera space\n    float k1 = 1.0/ projectedCoordEnd.w;\n\n    // calculate the reflection direction in the screen space\n    vec2 projectedCoordDir = (projectedCoordEnd.xy - projectedCoordStart.xy);\n    vec2 projectedCoordDistVanishingPoint = (projectedCoordVanishingPoint.xy - projectedCoordStart.xy);\n\n    float yMod = min(abs(projectedCoordDistVanishingPoint.y), 1.0);\n\n    float projectedCoordDirLength = length(projectedCoordDir);\n    float maxSt = float(maxSteps);\n\n    // normalize the projection direction depending on maximum steps\n    // this determines how blocky the reflection looks\n    vec2 dP = yMod * (projectedCoordDir)/(maxSt * projectedCoordDirLength);\n\n    // Normalize the homogeneous camera space coordinates\n    vec3  dQ = yMod * (Q1 - Q0)/(maxSt * projectedCoordDirLength);\n    float dk = yMod * (k1 - k0)/(maxSt * projectedCoordDirLength);\n\n    // initialize the variables for ray marching\n    vec2 P = projectedCoordStart.xy;\n    vec3 Q = Q0;\n    float k = k0;\n    float rayStartZ = -startPosition.z; // estimated ray start depth value\n    float rayEndZ = -startPosition.z;   // estimated ray end depth value\n    float prevEstimateZ = -startPosition.z;\n    float rayDiffZ = 0.0;\n    float dDepth;\n    float depth;\n    float rayDiffZOld = 0.0;\n\n    // early outs\n    if (dot(normal, dir) < 0.0 || dot(-viewDir, normal) < 0.0)\n      return vec3(P, 0.0);\n\n    for(int i = 0; i < maxSteps-1; i++)\n    {\n      depth = -linearDepthFromTexture(depthMapView, P, nearFar); // get linear depth from the depth buffer\n\n      // estimate depth of the marching ray\n      rayStartZ = prevEstimateZ;\n      dDepth = -rayStartZ - depth;\n      rayEndZ = (dQ.z * 0.5 + Q.z)/ ((dk * 0.5 + k));\n      rayDiffZ = rayEndZ- rayStartZ;\n      prevEstimateZ = rayEndZ;\n\n      if(-rayEndZ > nearFar[1] || -rayEndZ < nearFar[0] || P.y < 0.0  || P.y > 1.0 )\n      {\n        return vec3(P, 0.);\n      }\n\n      // If we detect a hit - return the intersection point, two conditions:\n      //  - dDepth > 0.0 - sampled point depth is in front of estimated depth\n      //  - if difference between dDepth and rayDiffZOld is not too large\n      //  - if difference between dDepth and 0.025/abs(k) is not too large\n      //  - if the sampled depth is not behind far plane or in front of near plane\n\n      if((dDepth) < 0.025/abs(k) + abs(rayDiffZ) && dDepth > 0.0 && depth > nearFar[0] && depth < nearFar[1] && abs(P.y - projectedCoordStart.y) > invResolutionHeight)\n      {\n          return vec3(P, depth);\n      }\n\n      // continue with ray marching\n      P += dP;\n      Q.z += dQ.z;\n      k += dk;\n      rayDiffZOld = rayDiffZ;\n    }\n    return vec3(P, 0.0);\n  }\n  `);\n}\n\nfunction i(e, t) {\n  t.ssrEnabled && (e.bindTexture(t.linearDepthTexture, \"depthMapView\"), e.setUniform2fv(\"nearFar\", t.camera.nearFar), e.setUniformMatrix4fv(\"ssrViewMat\", t.camera.viewMatrix), e.setUniform1f(\"invResolutionHeight\", 1 / t.camera.height), o(e, t));\n}\n\nexport { a as ScreenSpaceReflections, i as bindSSRUniforms };","map":{"version":3,"sources":["/Users/xiaoyuzhu/Desktop/arcgis-api-react/node_modules/@arcgis/core/views/3d/webgl-engine/core/shaderLibrary/shading/ScreenSpaceReflections.glsl.js"],"names":["ReadLinearDepth","e","Reprojection","t","bindReprojectionUniforms","o","glsl","r","a","fragment","uniforms","add","include","code","highStepCount","i","ssrEnabled","bindTexture","linearDepthTexture","setUniform2fv","camera","nearFar","setUniformMatrix4fv","viewMatrix","setUniform1f","height","ScreenSpaceReflections","bindSSRUniforms"],"mappings":"AAAA;AACA;AACA;AACA;AACA,SAAOA,eAAe,IAAIC,CAA1B,QAAgC,mCAAhC;AAAoE,SAAOC,YAAY,IAAIC,CAAvB,EAAyBC,wBAAwB,IAAIC,CAArD,QAA2D,wBAA3D;AAAoF,SAAOC,IAAI,IAAIC,CAAf,QAAqB,mCAArB;;AAAyD,SAASC,CAAT,CAAWH,CAAX,EAAaG,CAAb,EAAe;AAACH,EAAAA,CAAC,CAACI,QAAF,CAAWC,QAAX,CAAoBC,GAApB,CAAwB,SAAxB,EAAkC,MAAlC,GAA0CN,CAAC,CAACI,QAAF,CAAWC,QAAX,CAAoBC,GAApB,CAAwB,cAAxB,EAAuC,WAAvC,CAA1C,EAA8FN,CAAC,CAACI,QAAF,CAAWC,QAAX,CAAoBC,GAApB,CAAwB,YAAxB,EAAqC,MAArC,CAA9F,EAA2IN,CAAC,CAACI,QAAF,CAAWC,QAAX,CAAoBC,GAApB,CAAwB,qBAAxB,EAA8C,OAA9C,CAA3I,EAAkMN,CAAC,CAACI,QAAF,CAAWG,OAAX,CAAmBX,CAAnB,CAAlM,EAAwNI,CAAC,CAACO,OAAF,CAAUT,CAAV,CAAxN,EAAqOE,CAAC,CAACI,QAAF,CAAWI,IAAX,CAAgBF,GAAhB,CAAoBJ,CAAE;AAC5d,yBAAyBC,CAAC,CAACM,aAAF,GAAgB,MAAhB,GAAuB,KAAM;AACtD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,GAnGsc,CAArO;AAmG5N;;AAAA,SAASC,CAAT,CAAWd,CAAX,EAAaE,CAAb,EAAe;AAACA,EAAAA,CAAC,CAACa,UAAF,KAAef,CAAC,CAACgB,WAAF,CAAcd,CAAC,CAACe,kBAAhB,EAAmC,cAAnC,GAAmDjB,CAAC,CAACkB,aAAF,CAAgB,SAAhB,EAA0BhB,CAAC,CAACiB,MAAF,CAASC,OAAnC,CAAnD,EAA+FpB,CAAC,CAACqB,mBAAF,CAAsB,YAAtB,EAAmCnB,CAAC,CAACiB,MAAF,CAASG,UAA5C,CAA/F,EAAuJtB,CAAC,CAACuB,YAAF,CAAe,qBAAf,EAAqC,IAAErB,CAAC,CAACiB,MAAF,CAASK,MAAhD,CAAvJ,EAA+MpB,CAAC,CAACJ,CAAD,EAAGE,CAAH,CAA/N;AAAsO;;AAAA,SAAOK,CAAC,IAAIkB,sBAAZ,EAAmCX,CAAC,IAAIY,eAAxC","sourcesContent":["/*\nAll material copyright ESRI, All Rights Reserved, unless otherwise specified.\nSee https://js.arcgis.com/4.20/esri/copyright.txt for details.\n*/\nimport{ReadLinearDepth as e}from\"../output/ReadLinearDepth.glsl.js\";import{Reprojection as t,bindReprojectionUniforms as o}from\"./Reprojection.glsl.js\";import{glsl as r}from\"../../shaderModules/interfaces.js\";function a(o,a){o.fragment.uniforms.add(\"nearFar\",\"vec2\"),o.fragment.uniforms.add(\"depthMapView\",\"sampler2D\"),o.fragment.uniforms.add(\"ssrViewMat\",\"mat4\"),o.fragment.uniforms.add(\"invResolutionHeight\",\"float\"),o.fragment.include(e),o.include(t),o.fragment.code.add(r`\n  const int maxSteps = ${a.highStepCount?\"150;\":\"75;\"}\n\n  vec4 applyProjectionMat(mat4 projectionMat, vec3 x)\n  {\n    vec4 projectedCoord =  projectionMat * vec4(x, 1.0);\n    projectedCoord.xy /= projectedCoord.w;\n    projectedCoord.xy = projectedCoord.xy*0.5 + 0.5;\n    return projectedCoord;\n  }\n\n  vec3 screenSpaceIntersection(vec3 dir, vec3 startPosition, vec3 viewDir, vec3 normal)\n  {\n    vec3 viewPos = startPosition;\n    vec3 viewPosEnd = startPosition;\n\n    // Project the start position to the screen\n    vec4 projectedCoordStart = applyProjectionMat(rpProjectionMat, viewPos);\n    vec3  Q0 = viewPos / projectedCoordStart.w; // homogeneous camera space\n    float k0 = 1.0/ projectedCoordStart.w;\n\n    // advance the position in the direction of the reflection\n    viewPos += dir;\n\n    vec4 projectedCoordVanishingPoint = applyProjectionMat(rpProjectionMat, dir);\n\n    // Project the advanced position to the screen\n    vec4 projectedCoordEnd = applyProjectionMat(rpProjectionMat, viewPos);\n    vec3  Q1 = viewPos / projectedCoordEnd.w; // homogeneous camera space\n    float k1 = 1.0/ projectedCoordEnd.w;\n\n    // calculate the reflection direction in the screen space\n    vec2 projectedCoordDir = (projectedCoordEnd.xy - projectedCoordStart.xy);\n    vec2 projectedCoordDistVanishingPoint = (projectedCoordVanishingPoint.xy - projectedCoordStart.xy);\n\n    float yMod = min(abs(projectedCoordDistVanishingPoint.y), 1.0);\n\n    float projectedCoordDirLength = length(projectedCoordDir);\n    float maxSt = float(maxSteps);\n\n    // normalize the projection direction depending on maximum steps\n    // this determines how blocky the reflection looks\n    vec2 dP = yMod * (projectedCoordDir)/(maxSt * projectedCoordDirLength);\n\n    // Normalize the homogeneous camera space coordinates\n    vec3  dQ = yMod * (Q1 - Q0)/(maxSt * projectedCoordDirLength);\n    float dk = yMod * (k1 - k0)/(maxSt * projectedCoordDirLength);\n\n    // initialize the variables for ray marching\n    vec2 P = projectedCoordStart.xy;\n    vec3 Q = Q0;\n    float k = k0;\n    float rayStartZ = -startPosition.z; // estimated ray start depth value\n    float rayEndZ = -startPosition.z;   // estimated ray end depth value\n    float prevEstimateZ = -startPosition.z;\n    float rayDiffZ = 0.0;\n    float dDepth;\n    float depth;\n    float rayDiffZOld = 0.0;\n\n    // early outs\n    if (dot(normal, dir) < 0.0 || dot(-viewDir, normal) < 0.0)\n      return vec3(P, 0.0);\n\n    for(int i = 0; i < maxSteps-1; i++)\n    {\n      depth = -linearDepthFromTexture(depthMapView, P, nearFar); // get linear depth from the depth buffer\n\n      // estimate depth of the marching ray\n      rayStartZ = prevEstimateZ;\n      dDepth = -rayStartZ - depth;\n      rayEndZ = (dQ.z * 0.5 + Q.z)/ ((dk * 0.5 + k));\n      rayDiffZ = rayEndZ- rayStartZ;\n      prevEstimateZ = rayEndZ;\n\n      if(-rayEndZ > nearFar[1] || -rayEndZ < nearFar[0] || P.y < 0.0  || P.y > 1.0 )\n      {\n        return vec3(P, 0.);\n      }\n\n      // If we detect a hit - return the intersection point, two conditions:\n      //  - dDepth > 0.0 - sampled point depth is in front of estimated depth\n      //  - if difference between dDepth and rayDiffZOld is not too large\n      //  - if difference between dDepth and 0.025/abs(k) is not too large\n      //  - if the sampled depth is not behind far plane or in front of near plane\n\n      if((dDepth) < 0.025/abs(k) + abs(rayDiffZ) && dDepth > 0.0 && depth > nearFar[0] && depth < nearFar[1] && abs(P.y - projectedCoordStart.y) > invResolutionHeight)\n      {\n          return vec3(P, depth);\n      }\n\n      // continue with ray marching\n      P += dP;\n      Q.z += dQ.z;\n      k += dk;\n      rayDiffZOld = rayDiffZ;\n    }\n    return vec3(P, 0.0);\n  }\n  `)}function i(e,t){t.ssrEnabled&&(e.bindTexture(t.linearDepthTexture,\"depthMapView\"),e.setUniform2fv(\"nearFar\",t.camera.nearFar),e.setUniformMatrix4fv(\"ssrViewMat\",t.camera.viewMatrix),e.setUniform1f(\"invResolutionHeight\",1/t.camera.height),o(e,t))}export{a as ScreenSpaceReflections,i as bindSSRUniforms};\n"]},"metadata":{},"sourceType":"module"}