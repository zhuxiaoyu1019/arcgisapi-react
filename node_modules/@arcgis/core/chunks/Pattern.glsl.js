/*
All material copyright ESRI, All Rights Reserved, unless otherwise specified.
See https://js.arcgis.com/4.20/esri/copyright.txt for details.
*/
import{Slice as e}from"../views/3d/webgl-engine/core/shaderLibrary/Slice.glsl.js";import{Transform as t}from"../views/3d/webgl-engine/core/shaderLibrary/Transform.glsl.js";import{VertexColor as a}from"../views/3d/webgl-engine/core/shaderLibrary/attributes/VertexColor.glsl.js";import{OutputDepth as o}from"../views/3d/webgl-engine/core/shaderLibrary/output/OutputDepth.glsl.js";import{OutputHighlight as r}from"../views/3d/webgl-engine/core/shaderLibrary/output/OutputHighlight.glsl.js";import{ReadLinearDepth as i}from"../views/3d/webgl-engine/core/shaderLibrary/output/ReadLinearDepth.glsl.js";import{multipassTerrainTest as n}from"../views/3d/webgl-engine/core/shaderLibrary/shading/MultipassTerrainTest.glsl.js";import{symbolAlphaCutoff as l}from"../views/3d/webgl-engine/core/shaderLibrary/util/AlphaDiscard.glsl.js";import{ColorConversion as c}from"../views/3d/webgl-engine/core/shaderLibrary/util/ColorConversion.glsl.js";import{glsl as d}from"../views/3d/webgl-engine/core/shaderModules/interfaces.js";import{ShaderBuilder as s}from"../views/3d/webgl-engine/core/shaderModules/ShaderBuilder.js";const p=.70710678118,v=p,u=.08715574274;function m(m){const f=new s;m.draped||f.extensions.add("GL_OES_standard_derivatives");const h=1===m.output;f.include(t,{linearDepth:h}),f.include(a,m),f.vertex.uniforms.add("proj","mat4"),f.vertex.uniforms.add("view","mat4"),h&&(f.include(o,m),f.vertex.uniforms.add("cameraNearFar","vec2"),f.varyings.add("linearDepth","float")),m.draped?f.vertex.uniforms.add("worldToScreenRatio","float"):(f.vertex.uniforms.add("worldToScreenPerDistanceRatio","float"),f.vertex.uniforms.add("camPos","vec3"),f.attributes.add("boundingRect","mat3")),f.attributes.add("position","vec3"),f.attributes.add("uvMapSpace","vec4"),f.varyings.add("vpos","vec3"),f.varyings.add("vuv","vec2"),m.multipassTerrainEnabled&&f.varyings.add("depth","float");const w=3===m.style||4===m.style||5===m.style;return w&&f.vertex.code.add(d`
      const mat2 rotate45 = mat2(${d.float(p)}, ${d.float(-v)},
                                 ${d.float(v)}, ${d.float(p)});
    `),m.draped||(f.vertex.code.add(d`vec3 projectPointToLineSegment(vec3 center, vec3 halfVector, vec3 point) {
float projectedLength = dot(halfVector, point - center) / dot(halfVector, halfVector);
return center + halfVector * clamp(projectedLength, -1.0, 1.0);
}`),f.vertex.code.add(d`vec3 intersectRayPlane(vec3 rayDir, vec3 rayOrigin, vec3 planeNormal, vec3 planePoint) {
float d = dot(planeNormal, planePoint);
float t = (d - dot(planeNormal, rayOrigin)) / dot(planeNormal, rayDir);
return rayOrigin + t * rayDir;
}`),f.vertex.code.add(d`
      float boundingRectDistanceToCamera() {
        vec3 center = vec3(boundingRect[0][0], boundingRect[0][1], boundingRect[0][2]);
        vec3 halfU = vec3(boundingRect[1][0], boundingRect[1][1], boundingRect[1][2]);
        vec3 halfV = vec3(boundingRect[2][0], boundingRect[2][1], boundingRect[2][2]);
        vec3 n = normalize(cross(halfU, halfV));

        vec3 viewDir = - vec3(view[0][2], view[1][2], view[2][2]);

        float viewAngle = dot(viewDir, n);
        float minViewAngle = ${d.float(u)};

        if (abs(viewAngle) < minViewAngle) {
          // view direction is (almost) parallel to plane -> clamp it to min angle
          float normalComponent = sign(viewAngle) * minViewAngle - viewAngle;
          viewDir = normalize(viewDir + normalComponent * n);
        }

        // intersect view direction with infinite plane that contains bounding rect
        vec3 planeProjected = intersectRayPlane(viewDir, camPos, n, center);

        // clip to bounds by projecting to u and v line segments individually
        vec3 uProjected = projectPointToLineSegment(center, halfU, planeProjected);
        vec3 vProjected = projectPointToLineSegment(center, halfV, planeProjected);

        // use to calculate the closest point to camera on bounding rect
        vec3 closestPoint = uProjected + vProjected - center;

        return length(closestPoint - camPos);
      }
    `)),f.vertex.code.add(d`
    vec2 scaledUV() {
      vec2 uv = uvMapSpace.xy ${w?" * rotate45":""};
      vec2 uvCellOrigin = uvMapSpace.zw ${w?" * rotate45":""};

      ${m.draped?d`
            float ratio = worldToScreenRatio;
          `:d`
            float distanceToCamera = boundingRectDistanceToCamera();
            float ratio = worldToScreenPerDistanceRatio / distanceToCamera;

            // Logarithmically discretize ratio to avoid jittering
            float step = 0.1;
            ratio = log(ratio);
            ratio = ceil(ratio / step) * step;
            ratio = exp(ratio);
          `}

      vec2 uvOffset = mod(uvCellOrigin * ratio, ${d.float(m.patternSpacing)});
      return uvOffset + (uv * ratio);
    }
  `),f.vertex.code.add(d`
    void main(void) {
      vuv = scaledUV();
      vpos = position;
      ${m.multipassTerrainEnabled?"depth = (view * vec4(vpos, 1.0)).z;":""}
      forwardNormalizedVertexColor();
      gl_Position = ${h?d`transformPositionWithDepth(proj, view, vpos, cameraNearFar, linearDepth);`:d`transformPosition(proj, view, vpos);`}
    }
  `),f.include(e,m),f.fragment.include(c),f.fragment.uniforms.add("matColor","vec4"),m.draped&&f.fragment.uniforms.add("texelSize","float"),4===m.output&&f.include(r),m.multipassTerrainEnabled&&(f.fragment.include(i),f.include(n,m)),4!==m.output&&(f.fragment.code.add(d`
      const float lineWidth = ${d.float(m.lineWidth)};
      const float spacing = ${d.float(m.patternSpacing)};
      const float spacingINV = ${d.float(1/m.patternSpacing)};

      float coverage(float p, float txlSize) {
        p = mod(p, spacing);

        float halfTxlSize = txlSize / 2.0;

        float start = p - halfTxlSize;
        float end = p + halfTxlSize;

        float coverage = (ceil(end * spacingINV) - floor(start * spacingINV)) * lineWidth;
        coverage -= min(lineWidth, mod(start, spacing));
        coverage -= max(lineWidth - mod(end, spacing), 0.0);

        return coverage / txlSize;
      }
    `),m.draped||f.fragment.code.add(d`const int maxSamples = 5;
float sample(float p) {
vec2 dxdy = abs(vec2(dFdx(p), dFdy(p)));
float fwidth = dxdy.x + dxdy.y;
ivec2 samples = 1 + ivec2(clamp(dxdy, 0.0, float(maxSamples - 1)));
vec2 invSamples = 1.0 / vec2(samples);
float accumulator = 0.0;
for (int j = 0; j < maxSamples; j++) {
if(j >= samples.y) {
break;
}
for (int i = 0; i < maxSamples; i++) {
if(i >= samples.x) {
break;
}
vec2 step = vec2(i,j) * invSamples - 0.5;
accumulator += coverage(p + step.x * dxdy.x + step.y * dxdy.y, fwidth);
}
}
accumulator /= float(samples.x * samples.y);
return accumulator;
}`)),f.fragment.code.add(d`
    void main() {
      discardBySlice(vpos);
      ${m.multipassTerrainEnabled?"terrainDepthTest(gl_FragCoord, depth);":""}
      vec4 color = ${m.attributeColor?"vColor * matColor;":"matColor;"}
      color = highlightSlice(color, vpos);

      ${4!==m.output?d`color.a *= ${g(m)};`:""}

      if (color.a < ${d.float(l)}) {
        discard;
      }

      ${7===m.output?d`gl_FragColor = vec4(color.a);`:""}

      ${0===m.output?d`gl_FragColor = color; ${m.OITEnabled?"gl_FragColor = premultiplyAlpha(gl_FragColor);":""}`:""}
      ${4===m.output?d`outputHighlight();`:""}
      ${1===m.output?d`outputDepth(linearDepth);`:""};
    }
  `),f}function g(e){function t(t){return e.draped?d`coverage(vuv.${t}, texelSize)`:d`sample(vuv.${t})`}switch(e.style){case 3:case 0:return t("y");case 4:case 1:return t("x");case 5:case 2:return d`
        1.0 - (1.0 - ${t("x")}) * (1.0 - ${t("y")})
      `;default:return"0.0"}}var f=Object.freeze({__proto__:null,build:m});export{f as P,m as b};
